# @package _global_

# EEG Classification with Cross-Validation Experiment Config
# Uses EEG-specific defaults for loaders, transforms, optimizer, scheduler, logging, trainer, callbacks, and logger

defaults:
  - _self_
  - override /datamodule: eeg.yaml
  - override /module: eeg_single.yaml
  - override /trainer: eeg_default.yaml
  - override /callbacks: eeg_default.yaml
  - override /logger: eeg_default.yaml
  - override /paths: default.yaml
  - override /extras: default.yaml
  - override /hydra: default.yaml

# Task name, determines output directory path
task_name: "eye-state_classification_cv"

# Tags to help you identify your experiments
tags: ["eeg", "classification", "eegnet", "cv"]

# Set False to skip model training
train: true

# Evaluate on test set, using best model weights achieved during training
test: false
save_state_dict: true

# Save predictions for train/valid/test dataloaders using best checkpoint
save_predictions: true

# Simply provide checkpoint path to resume training
ckpt_path: null

# Seed for random number generators in pytorch, numpy and python.random
seed: 42

# Name of the run, accessed by loggers (includes date and will have _fold suffix for CV)
name: "eeg-classification-cv_${now:%Y-%m-%d}_${now:%H-%M}"

# Cross-validation configuration
cv:
  enabled: true
  # n_splits: 5  # Ignored for LeaveOneGroupOut
  strategy: "LeaveOneGroupOut"  # Leave-one-subject-out cross-validation
  shuffle: false  # Not applicable for LeaveOneGroupOut
  random_state: 42  # Not applicable for LeaveOneGroupOut
  group_column: "subject_id"

# Class names for confusion matrix logging
class_names: ["closed", "opened"]
num_classes: 2

# DataModule configuration
# Note: datasets.train should point to the COMBINED train+val dataset
# datasets.valid will be ignored when CV is enabled
# Uses eeg.yaml defaults for loaders and transforms
datamodule:
  _target_: src.datamodules.cv_datamodule.CrossValidationDataModule
  cv: ${cv}

  datasets:
    train:
      _target_: src.datamodules.datasets.ClassificationDataset
      # IMPORTANT: This should be the combined train+val dataset
      data_path: ${paths.data_dir}/classification/raw/crops_v2_500hz_30ch_5sec.parquet
      path_column: crop_path
      target_column: target
      read_mode: npy
      include_names: true
      label_type: "torch.LongTensor"

    # valid is ignored when CV is enabled, but kept for compatibility
    valid:
      _target_: src.datamodules.datasets.ClassificationDataset
      data_path: ${paths.data_dir}/classification/raw/crops_v2_500hz_30ch_5sec.parquet
      path_column: crop_path
      target_column: target
      read_mode: npy
      include_names: true
      label_type: "torch.LongTensor"

    test: null

# Module configuration
# Uses eeg_single.yaml defaults for optimizer, scheduler, and logging
module:
  class_names: ${class_names}
  num_classes: ${num_classes}

  network:
    model:
      _target_: src.modules.models.small_eeg_net.SmallEEGNet
      num_channels: 30
      signal_length: 2500
      num_classes: ${num_classes}

    loss:
      _target_: "src.modules.losses.components.focal_loss_with_label_smoothing.FocalLossWithLabelSmoothing"
      gamma: 2.0
      label_smoothing: 0.1
      reduction: "mean"

    metrics:
      main:
        _target_: "torchmetrics.AUROC"
        task: "multiclass"
        num_classes: ${num_classes}
        average: "macro"
      valid_best:
        _target_: "torchmetrics.MaxMetric"
      additional:
        BalancedAccuracy:
          _target_: "src.modules.metrics.components.classification.BalancedAccuracy"
          task: "multiclass"
          num_classes: ${num_classes}
        MAP:
          _target_: "src.modules.metrics.components.classification.MeanAveragePrecision"
          task: "multiclass"
          num_classes: ${num_classes}
        ConfusionMatrix:
          _target_: "src.modules.metrics.components.classification.ConfusionMatrixMetric"
          task: "multiclass"
          num_classes: ${num_classes}
          class_names: ${class_names}
          split: "train"  # Will be set correctly for each split in single_module
        NLL:
          _target_: "src.modules.metrics.components.classification.NegativeLogLikelihood"
          task: "multiclass"
          num_classes: ${num_classes}
          split: "train"  # Will be set correctly for each split in single_module

    output_activation:
      _target_: "torch.softmax"
      dim: 1

# Trainer configuration - only experiment-specific overrides
trainer:
  max_epochs: 10
  accelerator: gpu
  devices: 1
  num_sanity_val_steps: 0  # Disable sanity checks to prevent Lightning from accessing dataloaders before setup_fold() completes

# Callbacks configuration - only experiment-specific overrides
callbacks:
  model_checkpoint:
    filename: ${replace:"epoch{epoch:03d}-loss_valid{__loss__/valid:.4f}-metric_valid{__metric__/valid_epoch:.4f}"}
    monitor: ${replace:"__metric__/valid_epoch"}

  early_stopping:
    monitor: ${replace:"__metric__/valid_epoch"}

