# @package _global_

# EEG Classification Experiment Config
# Uses EEG-specific defaults for loaders, transforms, optimizer, scheduler, logging, trainer, callbacks, and logger

defaults:
  - override /datamodule: eeg.yaml
  - override /module: eeg_single.yaml
  - override /trainer: eeg_default.yaml
  - override /callbacks: eeg_default.yaml
  - override /logger: eeg_default.yaml
  - override /paths: default.yaml
  - override /extras: default.yaml
  - override /hydra: default.yaml

# Task name, determines output directory path
task_name: "eye-state_classification"

# Tags to help you identify your experiments
tags: ["eeg", "classification", "eegnet"]

# Set False to skip model training
train: true

# Evaluate on test set, using best model weights achieved during training
test: true
save_state_dict: true

# Simply provide checkpoint path to resume training
ckpt_path: null

# Seed for random number generators in pytorch, numpy and python.random
seed: 42

# Name of the run, accessed by loggers (includes date)
name: "eeg-classification_${now:%Y-%m-%d}_${now:%H-%M}"

# Class names for confusion matrix logging
class_names: ["S1", "S2"]
num_classes: 2

# DataModule configuration
# Uses eeg.yaml defaults for loaders and transforms
datamodule:
  datasets:
    train:
      _target_: src.datamodules.datasets.ClassificationDataset
      data_path: ${paths.data_dir}/classification/processed/crops_500_30_v1_train.parquet
      path_column: crop_path
      target_column: target
      read_mode: npy
      include_names: false
      label_type: "torch.LongTensor"

    valid:
      _target_: src.datamodules.datasets.ClassificationDataset
      data_path: ${paths.data_dir}/classification/processed/crops_500_30_v1_valid.parquet
      path_column: crop_path
      target_column: target
      read_mode: npy
      include_names: false
      label_type: "torch.LongTensor"

    test:
      _target_: src.datamodules.datasets.ClassificationDataset
      data_path: ${paths.data_dir}/classification/processed/crops_500_30_v1_valid.parquet
      path_column: crop_path
      target_column: target
      read_mode: npy
      include_names: false
      label_type: "torch.LongTensor"

# Module configuration
# Uses eeg_single.yaml defaults for optimizer, scheduler, and logging
module:
  class_names: ${class_names}
  num_classes: ${num_classes

  network:
    model:
      _target_: src.modules.models.small_eeg_net.SmallEEGNet
      num_channels: 30
      signal_length: 2500
      num_classes: ${num_classes}

    loss:
      _target_: "src.modules.losses.components.focal_loss_with_label_smoothing.FocalLossWithLabelSmoothing"
      gamma: 2.0
      label_smoothing: 0.1
      reduction: "mean"

    metrics:
      main:
        _target_: "src.modules.metrics.components.classification.BalancedAccuracy"
        task: "multiclass"
        num_classes: ${num_classes}
      valid_best:
        _target_: "torchmetrics.MaxMetric"
      additional:
        AUROC:
          _target_: "torchmetrics.AUROC"
          task: "multiclass"
          num_classes: ${num_classes}
        ConfusionMatrix:
          _target_: "src.modules.metrics.components.classification.ConfusionMatrixMetric"
          task: "multiclass"
          num_classes: ${num_classes}
          class_names: ${class_names}
          split: "train"  # Will be set correctly for each split in single_module

    output_activation:
      _target_: "torch.softmax"
      dim: 1

# Trainer configuration - only experiment-specific overrides
trainer:
  max_epochs: 10
  accelerator: gpu
  devices: 1

# Callbacks configuration - only experiment-specific overrides
callbacks:
  model_checkpoint:
    filename: "epoch{epoch:03d}-loss_valid{FocalLossWithLabelSmoothing/valid:.4f}-metric_valid{BalancedAccuracy/valid_epoch:.4f}"
    monitor: BalancedAccuracy/valid_epoch

  early_stopping:
    monitor: BalancedAccuracy/valid_epoch
